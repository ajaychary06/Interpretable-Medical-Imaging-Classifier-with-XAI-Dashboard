{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e5a2d1-7bf8-4fb3-b71f-65e7843ad844",
   "metadata": {},
   "source": [
    "# Final Report — Brain Tumor XAI (Improved)\n",
    "**Author:** Ajaychary Kandukuri\n",
    "\n",
    "This notebook reproduces evaluation and visualizes explainability outputs (Grad-CAM, Integrated Gradients) for the Brain Tumor XAI project.\n",
    "\n",
    "**Notes**\n",
    "- Run cells from top to bottom.\n",
    "- Paths assume your repo root contains: `data/processed`, `checkpoints/best_model.pth`, `outputs/xai_demo_from_train` and `outputs/streamlit_xai`.\n",
    "- If the notebook is inside `reports/`, the first code cell will adjust the working directory to project root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4573fefd-4396-4ffd-a837-50b43f0696e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to project root: C:\\Users\\ajayc\\Documents\\xai_brain_tumor\n",
      "Paths:\n",
      " DATA_ROOT: C:\\Users\\ajayc\\Documents\\xai_brain_tumor\\data\\processed\n",
      " CHECKPOINT: C:\\Users\\ajayc\\Documents\\xai_brain_tumor\\checkpoints\\best_model.pth\n",
      " OUT_XAI_TRAIN: C:\\Users\\ajayc\\Documents\\xai_brain_tumor\\outputs\\xai_demo_from_train\n",
      " OUT_XAI_STREAM: C:\\Users\\ajayc\\Documents\\xai_brain_tumor\\outputs\\streamlit_xai\n"
     ]
    }
   ],
   "source": [
    "# Environment & imports — robust to cwd / import problems\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Detect project root and set cwd so relative paths work whether notebook sits in /reports or repo root\n",
    "NB_PATH = Path.cwd()\n",
    "if (NB_PATH / \"scripts\").exists() and (NB_PATH / \"data\").exists():\n",
    "    PROJECT_ROOT = NB_PATH\n",
    "elif (NB_PATH / \"..\" / \"scripts\").resolve().exists():\n",
    "    PROJECT_ROOT = (NB_PATH / \"..\").resolve()\n",
    "else:\n",
    "    # fallback: assume current working dir is project root\n",
    "    PROJECT_ROOT = NB_PATH\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"Working directory set to project root:\", PROJECT_ROOT)\n",
    "\n",
    "# Paths used throughout the notebook\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "CHECKPOINT = PROJECT_ROOT / \"checkpoints\" / \"best_model.pth\"\n",
    "OUT_XAI_TRAIN = PROJECT_ROOT / \"outputs\" / \"xai_demo_from_train\"\n",
    "OUT_XAI_STREAM = PROJECT_ROOT / \"outputs\" / \"streamlit_xai\"\n",
    "\n",
    "print(\"Paths:\")\n",
    "print(\" DATA_ROOT:\", DATA_ROOT)\n",
    "print(\" CHECKPOINT:\", CHECKPOINT)\n",
    "print(\" OUT_XAI_TRAIN:\", OUT_XAI_TRAIN)\n",
    "print(\" OUT_XAI_STREAM:\", OUT_XAI_STREAM)\n",
    "\n",
    "# Ensure matplotlib inline display\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b216687-23cf-4799-ade9-3fef463c98e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\Newfolder\\envs\\xai_proj\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded explain_image_with_models: True\n"
     ]
    }
   ],
   "source": [
    "# Dynamic import of scripts/xai_extended.py so notebook won't fail due to sys.path issues\n",
    "import importlib.util\n",
    "XAI_PATH = PROJECT_ROOT / \"scripts\" / \"xai_extended.py\"\n",
    "if not XAI_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Expected xai_extended.py at {XAI_PATH}; please ensure file exists.\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"xai_extended\", str(XAI_PATH))\n",
    "xai_mod = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(xai_mod)\n",
    "\n",
    "# Functions we'll use\n",
    "load_model = getattr(xai_mod, \"load_model\", None)\n",
    "explain_image_with_models = getattr(xai_mod, \"explain_image_with_models\", None)\n",
    "print(\"Loaded explain_image_with_models:\", explain_image_with_models is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5eb913-fc13-474b-8479-3b7e5d25e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset counts and sample images\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def class_counts(folder: Path):\n",
    "    if not folder.exists():\n",
    "        return {}\n",
    "    counts = {}\n",
    "    for d in sorted([p for p in folder.iterdir() if p.is_dir()]):\n",
    "        counts[d.name] = len(list(d.glob(\"*.*\")))\n",
    "    return counts\n",
    "\n",
    "print(\"Train counts:\", class_counts(DATA_ROOT / \"train\"))\n",
    "print(\"Val counts:  \", class_counts(DATA_ROOT / \"val\"))\n",
    "print(\"Test counts: \", class_counts(DATA_ROOT / \"test\"))\n",
    "\n",
    "# Show up to 4 samples from each class in test\n",
    "fig, axs = plt.subplots(2,4, figsize=(12,6))\n",
    "for i, cls in enumerate([\"yes\",\"no\"]):\n",
    "    folder = DATA_ROOT / \"test\" / cls\n",
    "    imgs = list(folder.glob(\"*.*\"))[:4] if folder.exists() else []\n",
    "    for j in range(4):\n",
    "        ax = axs[i,j]\n",
    "        ax.axis(\"off\")\n",
    "        if j < len(imgs):\n",
    "            im = Image.open(imgs[j]).convert(\"RGB\")\n",
    "            ax.imshow(im)\n",
    "            ax.set_title(f\"{cls}/{imgs[j].name}\", fontsize=8)\n",
    "        else:\n",
    "            ax.set_title(\"---\")\n",
    "plt.suptitle(\"Sample test images (yes / no)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e62930-d79b-461c-b44d-6c4af7e96ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet-18 skeleton and load checkpoint (tolerant)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "print(\"Model created. Device:\", device)\n",
    "\n",
    "if CHECKPOINT.exists():\n",
    "    print(\"Loading checkpoint:\", CHECKPOINT)\n",
    "    state = torch.load(str(CHECKPOINT), map_location=device)\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        sd = state[\"state_dict\"]\n",
    "    else:\n",
    "        sd = state\n",
    "    if isinstance(sd, dict):\n",
    "        sd = {k.replace(\"module.\",\"\"): v for k, v in sd.items()}\n",
    "    try:\n",
    "        model.load_state_dict(sd, strict=False)\n",
    "        print(\"Checkpoint loaded (len state_dict) =\", len(sd) if isinstance(sd, dict) else \"unknown\")\n",
    "    except Exception as e:\n",
    "        print(\"Warning: loading checkpoint raised:\", e)\n",
    "        model.load_state_dict(sd, strict=False)\n",
    "else:\n",
    "    print(\"No checkpoint found at\", CHECKPOINT, \"-- evaluation will use untrained skeleton.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16a93e-d122-4ef2-b65a-667a27ffd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test loader and evaluate\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "test_dir = DATA_ROOT / \"test\"\n",
    "if not test_dir.exists():\n",
    "    raise FileNotFoundError(f\"Expected test folder at {test_dir}\")\n",
    "\n",
    "test_ds = datasets.ImageFolder(str(test_dir), transform=transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outs = model(imgs)\n",
    "        preds = outs.argmax(dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds.tolist())\n",
    "        y_true.extend(labels.numpy().tolist())\n",
    "\n",
    "if len(y_true) == 0:\n",
    "    print(\"No test samples found.\")\n",
    "else:\n",
    "    acc = sum(int(a==b) for a,b in zip(y_true,y_pred)) / len(y_true)\n",
    "    print(f\"Test accuracy: {acc:.4f} ({sum(int(a==b) for a,b in zip(y_true,y_pred))}/{len(y_true)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40344e37-7a47-4296-bd49-7d2861afcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "labels = test_ds.classes if hasattr(test_ds, \"classes\") else [str(i) for i in range(num_classes)]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=labels, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ecee9-bcbd-4f61-9ddb-0bf4729edf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display saved XAI overlays and optionally re-run explainers on a sample\n",
    "from IPython.display import display\n",
    "\n",
    "def show_folder(folder: Path, n=8):\n",
    "    if not folder.exists():\n",
    "        print(\"Folder not found:\", folder); return\n",
    "    files = sorted(list(folder.glob(\"*.*\")))\n",
    "    print(f\"{len(files)} files in {folder}; showing up to {n}\")\n",
    "    for f in files[:n]:\n",
    "        print(\"-\", f.name)\n",
    "        display(Image.open(f))\n",
    "\n",
    "print(\"Overlays from training run:\")\n",
    "show_folder(OUT_XAI_TRAIN, n=12)\n",
    "\n",
    "print(\"\\nOverlays from Streamlit run:\")\n",
    "show_folder(OUT_XAI_STREAM, n=12)\n",
    "\n",
    "# Optionally re-run explainers on a chosen sample (first available sample)\n",
    "sample = None\n",
    "yes_list = list((DATA_ROOT/\"test\"/\"yes\").glob(\"*.*\")) if (DATA_ROOT/\"test\"/\"yes\").exists() else []\n",
    "no_list  = list((DATA_ROOT/\"test\"/\"no\").glob(\"*.*\")) if (DATA_ROOT/\"test\"/\"no\").exists() else []\n",
    "if yes_list:\n",
    "    sample = str(yes_list[0])\n",
    "elif no_list:\n",
    "    sample = str(no_list[0])\n",
    "\n",
    "if sample:\n",
    "    print(\"Re-running explainers on:\", sample)\n",
    "    try:\n",
    "        res = explain_image_with_models(sample, model=model, use_gradcam=True, use_ig=True)\n",
    "        if res.get(\"original_pil\") is not None:\n",
    "            display(res[\"original_pil\"])\n",
    "        if res.get(\"gradcam_overlay\") is not None:\n",
    "            display(res[\"gradcam_overlay\"])\n",
    "        if res.get(\"ig_overlay\") is not None:\n",
    "            display(res[\"ig_overlay\"])\n",
    "    except Exception as e:\n",
    "        print(\"Explainers failed:\", e)\n",
    "else:\n",
    "    print(\"No sample available to re-run explainers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7884f91-d836-438b-afe3-45e7d6995a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you saved a CSV training log (epoch, train_loss, val_loss, val_acc), show curves\n",
    "log_path = PROJECT_ROOT / \"outputs\" / \"training_log.csv\"\n",
    "if log_path.exists():\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(log_path)\n",
    "    df.plot(x=\"epoch\", y=[\"train_loss\",\"val_loss\"], marker='o', figsize=(8,4)); plt.title(\"Loss curves\"); plt.show()\n",
    "    df.plot(x=\"epoch\", y=\"val_acc\", marker='o', figsize=(6,3)); plt.title(\"Validation accuracy\"); plt.show()\n",
    "else:\n",
    "    print(\"No training log found at\", log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ff9cd-0c12-470a-a0e6-3f8fd61df9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick troubleshooting outputs\n",
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Working dir:\", Path.cwd())\n",
    "print(\"scripts/xai_extended.py exists:\", (PROJECT_ROOT / \"scripts\" / \"xai_extended.py\").exists())\n",
    "print(\"checkpoint exists:\", CHECKPOINT.exists())\n",
    "print(\"data/processed/test exists:\", (DATA_ROOT / \"test\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dad85c-97b3-4e48-952b-1b7224bfc2b4",
   "metadata": {},
   "source": [
    "## Interpretation, limitations & next steps\n",
    "\n",
    "**Interpretation**\n",
    "- Test accuracy (see above) indicates the model's current performance on provided test split.\n",
    "- Grad-CAM and Integrated Gradients overlays help highlight image regions contributing to the prediction.\n",
    "\n",
    "**Limitations**\n",
    "- Dataset size and class balance may bias the model.\n",
    "- Model trained on 2D slices; volumetric (3D) MRIs require different handling.\n",
    "- Evaluation uses a single split — cross-validation would provide more robust performance estimates.\n",
    "\n",
    "**Next steps**\n",
    "1. Log training metrics (CSV/TensorBoard) and include training curves.\n",
    "2. Add k-fold cross-validation.\n",
    "3. Experiment with domain pretraining or medical-image-specific backbones.\n",
    "4. Add uncertainty estimation and calibration.\n",
    "5. Prepare README + environment files and push to GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469aedd-e77e-4585-b7af-fb1983079e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xai_proj)",
   "language": "python",
   "name": "xai_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
