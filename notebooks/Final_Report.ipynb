{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg_Tpgg_06OL"
      },
      "outputs": [],
      "source": [
        "# 1.1: Activate env (run in terminal)\n",
        "# conda activate xai_proj\n",
        "\n",
        "\n",
        "# 1.2: imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torchvision\n",
        "print('torch', torch.__version__)\n",
        "\n",
        "\n",
        "# 1.3: constants\n",
        "PROJECT_ROOT = Path.cwd().resolve()\n",
        "DATA_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "CHECKPOINT = PROJECT_ROOT / 'checkpoints' / 'best_model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 class counts\n",
        "from collections import Counter\n",
        "for split in ['train','val','test']:\n",
        "p = DATA_DIR / split\n",
        "classes = [d.name for d in p.iterdir() if d.is_dir()]\n",
        "counts = {c: len(list((p/c).glob('*.*'))) for c in classes}\n",
        "print(split, counts)\n",
        "\n",
        "\n",
        "# 2.2 show sample images\n",
        "from PIL import Image\n",
        "fig, axes = plt.subplots(2,4, figsize=(12,6))\n",
        "imgs = []\n",
        "for i,c in enumerate(sorted((DATA_DIR/'train').iterdir())):\n",
        "if i>=4: break\n",
        "sample = next((DATA_DIR/'train'/c.name).glob('*.*'))\n",
        "img = Image.open(sample).convert('RGB')\n",
        "axes[0,i].imshow(img)\n",
        "axes[0,i].axis('off')\n",
        "axes[0,i].set_title(c.name)\n",
        "\n",
        "\n",
        "# show more random examples"
      ],
      "metadata": {
        "id": "Q3mfdfOB1DDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 load training logs if any (TensorBoard logs or manual CSV)\n",
        "# If you logged to CSV, load and plot\n",
        "log_csv = PROJECT_ROOT / 'results' / 'training_log.csv'\n",
        "if log_csv.exists():\n",
        "df = pd.read_csv(log_csv)\n",
        "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
        "sns.lineplot(data=df, x='epoch', y='train_loss', ax=ax[0], label='train')\n",
        "sns.lineplot(data=df, x='epoch', y='val_loss', ax=ax[0], label='val')\n",
        "sns.lineplot(data=df, x='epoch', y='train_acc', ax=ax[1], label='train')\n",
        "sns.lineplot(data=df, x='epoch', y='val_acc', ax=ax[1], label='val')\n",
        "\n",
        "\n",
        "# 3.2 model summary (load model and print)\n",
        "import importlib.util\n",
        "spec = importlib.util.spec_from_file_location('model_mod', PROJECT_ROOT/'src'/'model.py')\n",
        "model_mod = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(model_mod)\n",
        "model = model_mod.get_resnet18(num_classes=2, pretrained=False)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "IJFnMs951Gk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_csv = RESULTS_DIR / 'predictions.csv'\n",
        "if pred_csv.exists():\n",
        "dfp = pd.read_csv(pred_csv)\n",
        "display(dfp.head())\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "cm_path = RESULTS_DIR / 'confusion_matrix.png'\n",
        "if cm_path.exists():\n",
        "display(Image.open(cm_path))"
      ],
      "metadata": {
        "id": "fy-rEMju1Jk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xai_dir = RESULTS_DIR/'xai'\n",
        "combined = sorted([p for p in xai_dir.glob('*_combined.png')])[:12]\n",
        "fig, axes = plt.subplots(4,3, figsize=(12,14))\n",
        "for ax, p in zip(axes.flatten(), combined):\n",
        "img = Image.open(p)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "ax.set_title(p.name)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "4d1EHKM51MR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uses numpy to open attribution arrays if you saved them, or recomputes on a few images\n",
        "# Pseudocode: load attributions, compute center mask, compute mean_in/mean_out"
      ],
      "metadata": {
        "id": "CwpsiGHY1QzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tVTXVE5X1BQj"
      }
    }
  ]
}